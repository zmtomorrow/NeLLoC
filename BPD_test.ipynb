{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPD test examples\n",
    "\n",
    "For the ImageNet examples, we use the standard datasets downloaded from https://image-net.org/download-images.php (login needed).\n",
    "* Val(32x32)\n",
    "* Val(64x64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "import torch.nn as nn\n",
    "from utils import *\n",
    "from model import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from scipy.io import loadmat\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion  = lambda real, fake : discretized_mix_logistic_uniform(real, fake, alpha=0.0001)\n",
    "rescaling     = lambda x : (x - .5) * 2.\n",
    "rescaling_inv = lambda x : .5 * x  + .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trained on CIFAR10 and test on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rs=0\n",
      "bpd_cifar 3.3833506457358866\n",
      "rs=1\n",
      "bpd_cifar 3.281978964854339\n",
      "rs=3\n",
      "bpd_cifar 3.2469579184385937\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='../../data/cifar10', train=False, download=False, transform=transforms.ToTensor())\n",
    "test = data.DataLoader(testset, batch_size=1000, shuffle=True, num_workers=3)\n",
    "def test_bpd(net):\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        bpd_cifar_sum=0.\n",
    "        for i, (images, labels) in enumerate(test):\n",
    "            images = rescaling(images).to(device)\n",
    "            output = net(images)\n",
    "            loss = criterion(images, output).item()\n",
    "            bpd_cifar_sum+=loss/(np.log(2.)*(1000*32*32*3))\n",
    "        bpd_cifar=bpd_cifar_sum/10\n",
    "        print('bpd_cifar',bpd_cifar)\n",
    "        \n",
    "net = LocalPixelCNN(res_num=0, in_kernel = 7,  in_channels=3, channels=256, out_channels=100).to(device)\n",
    "net.load_state_dict(torch.load('./model_save/rs0_cifar_h3.pt'))\n",
    "print('rs=0')\n",
    "test_bpd(net)\n",
    "net = LocalPixelCNN(res_num=1, in_kernel = 7,  in_channels=3, channels=256, out_channels=100).to(device)\n",
    "net.load_state_dict(torch.load('./model_save/rs1_cifar_h3.pt'))\n",
    "print('rs=1')\n",
    "test_bpd(net)\n",
    "net = LocalPixelCNN(res_num=3, in_kernel = 7,  in_channels=3, channels=256, out_channels=100).to(device)\n",
    "net.load_state_dict(torch.load('./model_save/rs3_cifar_h3.pt'))\n",
    "print('rs=3')\n",
    "test_bpd(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trained on Imagenet32 and test on Imagenet32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test set is 153737544 bytes\n",
      "shape of test set torch.Size([50000, 3, 32, 32])\n",
      "rs=0\n",
      "bpd_img32 3.9364352346796125\n",
      "rs=1\n",
      "bpd_img32 3.848284853541681\n",
      "rs=3\n",
      "bpd_img32 3.8112208203916493\n"
     ]
    }
   ],
   "source": [
    "data_file = '/mnt/data/img32/val_data'\n",
    "size = os.path.getsize('/mnt/data/img32/val_data') \n",
    "print('Size of test set is', size, 'bytes')\n",
    "d = unpickle(data_file)\n",
    "x = d['data'].reshape(-1,3,32,32)\n",
    "test_img32=torch.tensor(x).float()[:,:,:,:]/255.\n",
    "print('shape of test set',test_img32.size())\n",
    "\n",
    "def test_bpd(net):\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        bpd_img32_sum=0.\n",
    "        for i in range(0,50):\n",
    "            images=rescaling(test_img32[i*1000:(i+1)*1000]).to(device)\n",
    "            output = net(images)\n",
    "            loss = criterion(images, output).item()\n",
    "            bpd_img32_sum+=loss/(np.log(2.)*(1000*32*32*3))\n",
    "        bpd_img32=bpd_img32_sum/50\n",
    "\n",
    "        print('bpd_img32',bpd_img32)\n",
    "        \n",
    "net = LocalPixelCNN(res_num=0, in_kernel = 7,  in_channels=3, channels=256, out_channels=100).to(device)\n",
    "net.load_state_dict(torch.load('./model_save/imgnet32_rs0_h3.pt'))\n",
    "print('rs=0')\n",
    "test_bpd(net)\n",
    "net = LocalPixelCNN(res_num=1, in_kernel = 7,  in_channels=3, channels=256, out_channels=100).to(device)\n",
    "net.load_state_dict(torch.load('./model_save/imgnet32_rs1_h3.pt'))\n",
    "print('rs=1')\n",
    "test_bpd(net)\n",
    "net = LocalPixelCNN(res_num=3, in_kernel = 7,  in_channels=3, channels=256, out_channels=100).to(device)\n",
    "net.load_state_dict(torch.load('./model_save/imgnet32_rs3_h3.pt'))\n",
    "print('rs=3')\n",
    "test_bpd(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trained on Imagenet32 and test on Imagenet64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test set is 529393262 bytes\n",
      "shape of test set torch.Size([50000, 3, 64, 64])\n",
      "rs=0\n",
      "bpd_img64 3.6325303754905924\n",
      "rs=1\n",
      "bpd_img64 3.549048025647982\n",
      "rs=3\n",
      "bpd_img64 3.5152607124355035\n"
     ]
    }
   ],
   "source": [
    "data_file = '/mnt/data/Imagenet64_val_npz/val_data.npz'\n",
    "size = os.path.getsize('/mnt/data/Imagenet64_val_npz/val_data.npz') \n",
    "print('Size of test set is', size, 'bytes')\n",
    "d = np.load(data_file)\n",
    "x = d['data'].reshape(-1,3,64,64)\n",
    "test_img32=torch.tensor(x).float()[:,:,:,:]/255.\n",
    "print('shape of test set',test_img32.size())\n",
    "\n",
    "def test_bpd(net):\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        bpd_img32_sum=0.\n",
    "        for i in range(0,500):\n",
    "            images=rescaling(test_img32[i*100:(i+1)*100]).to(device)\n",
    "            output = net(images)\n",
    "            loss = criterion(images, output).item()\n",
    "            bpd_img32_sum+=loss/(np.log(2.)*(100*64*64*3))\n",
    "        bpd_img32=bpd_img32_sum/500\n",
    "\n",
    "        print('bpd_img64',bpd_img32)\n",
    "        \n",
    "net = LocalPixelCNN(res_num=0, in_kernel = 7,  in_channels=3, channels=256, out_channels=100).to(device)\n",
    "net.load_state_dict(torch.load('./model_save/imgnet32_rs0_h3.pt'))\n",
    "print('rs=0')\n",
    "test_bpd(net)\n",
    "net = LocalPixelCNN(res_num=1, in_kernel = 7,  in_channels=3, channels=256, out_channels=100).to(device)\n",
    "net.load_state_dict(torch.load('./model_save/imgnet32_rs1_h3.pt'))\n",
    "print('rs=1')\n",
    "test_bpd(net)\n",
    "net = LocalPixelCNN(res_num=3, in_kernel = 7,  in_channels=3, channels=256, out_channels=100).to(device)\n",
    "net.load_state_dict(torch.load('./model_save/imgnet32_rs3_h3.pt'))\n",
    "print('rs=3')\n",
    "test_bpd(net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
